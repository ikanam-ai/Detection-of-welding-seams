{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-03-14T03:21:24.942887Z","iopub.status.busy":"2023-03-14T03:21:24.942429Z","iopub.status.idle":"2023-03-14T03:21:25.038709Z","shell.execute_reply":"2023-03-14T03:21:25.037004Z","shell.execute_reply.started":"2023-03-14T03:21:24.942844Z"},"trusted":true},"outputs":[],"source":["# This Python code converts a dataset in YOLO format into the COCO format. \n","# The YOLO dataset contains images of bottles and the bounding box annotations in the \n","# YOLO format. The COCO format is a widely used format for object detection datasets.\n","\n","# The input and output directories are specified in the code. The categories for \n","# the COCO dataset are also defined, with only one category for \"bottle\". A dictionary for the COCO dataset is initialized with empty values for \"info\", \"licenses\", \"images\", and \"annotations\".\n","\n","# The code then loops through each image in the input directory. The dimensions \n","# of the image are extracted and added to the COCO dataset as an \"image\" dictionary, \n","# including the file name and an ID. The bounding box annotations for each image are \n","# read from a text file with the same name as the image file, and the coordinates are \n","# converted to the COCO format. The annotations are added to the COCO dataset as an \n","# \"annotation\" dictionary, including an ID, image ID, category ID, bounding box coordinates,\n","# area, and an \"iscrowd\" flag.\n","\n","# The COCO dataset is saved as a JSON file in the output directory.\n","\n","  0: \"crazing\"\n","  1: \"inclusion\"\n","  2: \"patches\"\n","  3: \"pitted_surface\"\n","  4: \"rolled-in\"\n","  5: \"scratches\"\n","\n","\n","import json\n","import os\n","from PIL import Image\n","\n","# Set the paths for the input and output directories\n","input_dir = '/path/to/yolo/dataset'\n","output_dir = '/path/to/coco/dataset'\n","\n","# Define the categories for the COCO dataset\n","categories = [{\"id\": 0, \"name\": \"bottle\"}]\n","\n","# Define the COCO dataset dictionary\n","coco_dataset = {\n","    \"info\": {},\n","    \"licenses\": [],\n","    \"categories\": categories,\n","    \"images\": [],\n","    \"annotations\": []\n","}\n","\n","# Loop through the images in the input directory\n","for image_file in os.listdir(input_dir):\n","    \n","    # Load the image and get its dimensions\n","    image_path = os.path.join(input_dir, image_file)\n","    image = Image.open(image_path)\n","    width, height = image.size\n","    \n","    # Add the image to the COCO dataset\n","    image_dict = {\n","        \"id\": int(image_file.split('.')[0]),\n","        \"width\": width,\n","        \"height\": height,\n","        \"file_name\": image_file\n","    }\n","    coco_dataset[\"images\"].append(image_dict)\n","    \n","    # Load the bounding box annotations for the image\n","    with open(os.path.join(input_dir, f'{image_file.split(\".\")[0]}.txt')) as f:\n","        annotations = f.readlines()\n","    \n","    # Loop through the annotations and add them to the COCO dataset\n","    for ann in annotations:\n","        x, y, w, h = map(float, ann.strip().split()[1:])\n","        x_min, y_min = int((x - w / 2) * width), int((y - h / 2) * height)\n","        x_max, y_max = int((x + w / 2) * width), int((y + h / 2) * height)\n","        ann_dict = {\n","            \"id\": len(coco_dataset[\"annotations\"]),\n","            \"image_id\": int(image_file.split('.')[0]),\n","            \"category_id\": 0,\n","            \"bbox\": [x_min, y_min, x_max - x_min, y_max - y_min],\n","            \"area\": (x_max - x_min) * (y_max - y_min),\n","            \"iscrowd\": 0\n","        }\n","        coco_dataset[\"annotations\"].append(ann_dict)\n","\n","# Save the COCO dataset to a JSON file\n","with open(os.path.join(output_dir, 'annotations.json'), 'w') as f:\n","    json.dump(coco_dataset, f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import json\n","import os\n","from PIL import Image\n","\n","# Set the paths for the input and output directories\n","input_dir = '/home/andrew/works/shpad_add/Detection-of-welding-seams/dataset_copy/train'\n","images_dir = os.path.join(input_dir, 'images')\n","labels_dir = os.path.join(input_dir, 'labels')\n","output_dir = '/home/andrew/works/shpad_add/Detection-of-welding-seams/coco_data/train'\n","\n","# Define the categories for the COCO dataset\n","categories = [\n","    {\"id\": 0, \"name\": \"crazing\"},\n","    {\"id\": 1, \"name\": \"inclusion\"},\n","    {\"id\": 2, \"name\": \"patches\"},\n","    {\"id\": 3, \"name\": \"pitted_surface\"},\n","    {\"id\": 4, \"name\": \"rolled-in\"},\n","    {\"id\": 5, \"name\": \"scratches\"}\n","]\n","\n","# Define the COCO dataset dictionary\n","coco_dataset = {\n","    \"info\": {},\n","    \"licenses\": [],\n","    \"categories\": categories,\n","    \"images\": [],\n","    \"annotations\": []\n","}\n","\n","# Function to get category ID by name\n","def get_category_id(name):\n","    for category in categories:\n","        if category[\"name\"] == name:\n","            return category[\"id\"]\n","    return None\n","\n","# Loop through the images in the input directory\n","for image_file in os.listdir(images_dir):\n","    if image_file.endswith('.jpg'):\n","        # Load the image and get its dimensions\n","        image_path = os.path.join(images_dir, image_file)\n","        image = Image.open(image_path)\n","        width, height = image.size\n","\n","        # Add the image to the COCO dataset\n","        image_id = int(image_file.split('.')[0].split()[0])\n","        image_dict = {\n","            \"id\": image_id,\n","            \"width\": width,\n","            \"height\": height,\n","            \"file_name\": image_file\n","        }\n","        coco_dataset[\"images\"].append(image_dict)\n","\n","        # Load the bounding box annotations for the image\n","        label_file = f'{image_file.split(\".\")[0]}.txt'\n","        label_path = os.path.join(labels_dir, label_file)\n","        if os.path.exists(label_path):\n","            with open(label_path) as f:\n","                annotations = f.readlines()\n","\n","            # Loop through the annotations and add them to the COCO dataset\n","            for ann in annotations:\n","                ann_parts = ann.strip().split()\n","                class_id = int(ann_parts[0])\n","                x, y, w, h = map(float, ann_parts[1:])\n","                x_min, y_min = int((x - w / 2) * width), int((y - h / 2) * height)\n","                x_max, y_max = int((x + w / 2) * width), int((y + h / 2) * height)\n","                ann_dict = {\n","                    \"id\": len(coco_dataset[\"annotations\"]),\n","                    \"image_id\": image_id,\n","                    \"category_id\": class_id,\n","                    \"bbox\": [x_min, y_min, x_max - x_min, y_max - y_min],\n","                    \"area\": (x_max - x_min) * (y_max - y_min),\n","                    \"iscrowd\": 0\n","                }\n","                coco_dataset[\"annotations\"].append(ann_dict)\n","\n","# Save the COCO dataset to a JSON file\n","os.makedirs(output_dir, exist_ok=True)\n","with open(os.path.join(output_dir, 'annotations.json'), 'w') as f:\n","    json.dump(coco_dataset, f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":4}
